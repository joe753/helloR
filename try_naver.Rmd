---
title: "try_naver"
output: html_document
---

```{r, echo=FALSE}
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_191/")
library(RColorBrewer)
library(wordcloud)
library(ROAuth)

library(KoNLP)
library(rJava)
library(arules); 
library(igraph); 
library(combinat)
library(arulesViz); 
library(visNetwork)

library('ggplot2')
library(rvest); 
library(httr); 
library(stringr); 
library(dplyr);
library(tm);



```


### 1.네이버 뉴스 1면의 기사들을 수집하시오.

```{r}
newsUrl = "https://news.naver.com/main/home.nhn"
newsUrl
html = read_html(newsUrl)
html
links = html_attr(html_nodes(html, '#main_content li a'), 'href')

links = links[!is.na(links)]
links = links
length(links)
links
# 
removeStopword = function(t) {
  t = gsub("[[:cntrl:]]", "", t)
  t = gsub("http[s]?://[[:alnum:].\\/]+", "", t)
  t = gsub("&[[:alnum:]]+;", "", t)
  t = gsub("@[[:alnum:]]+", "", t)
  t = gsub("@[[:alnum:]]+[:]?", "", t)
  # t = gsub("[ㄱ-ㅎㅏ-ㅣ]","",t)
  t = gsub("\\s{2,}", " ", t)
  t = gsub("[[:punct:]]", "", t)
  t = gsub("https", "", t)
  t = gsub("RT", "", t)
  t = gsub("\\s{2,}", " ", t)
  t = gsub('[[:alnum:]]+@[[:alnum:].]+', '', t)
}

news = list()


for (i in 1:length(links)) {
  try({
    htxt = read_html(links[i])
    comments = html_nodes(htxt, '#articleBodyContents')
    get_news = repair_encoding(html_text(comments))   # repair_encoding(html_text(comments), from='utf-8')
    news[i] = str_trim(get_news)
  }, silent = F)
}


for (i in 1:length(news)) {
  if (is.null (news[[i]][1])) next
  news[[i]][1] = removeStopword(news[[i]][1])
  news[[i]][1] = gsub(" flash 오류를 우회하기 위한 함수 추가function flashremoveCallback", "", news[[i]][1])
}

cc = c()
for (j in 1:length(news)) {
  if (length(news[[j]]) == 0) next

  cc = c(cc, news[j])
}

```



### 2. 수집 된 뉴스로 WordCloud를 작도하시오.

```{r }
wc = sapply(cc, extractNoun, USE.NAMES = F)
ul = unlist(wc)
ul = ul[nchar(ul) > 1]
wc1 = table(ul)
wc2 = head(sort(wc1, decreasing = T), 100)

pal = brewer.pal(9, "Set1")
wordcloud(names(wc2), freq=wc2, scale=c(3,0.5), rot.per=0.25,
          min.freq = 1, random.order = F, random.color = T, colors = pal)

```

### 3. 수집 된 뉴스로 연관성분석을 하시오.

```{r}
wc = sapply(cc, extractNoun, USE.NAMES = F)
nouns = unique(wc)
nouns = sapply(wc, unique)
# 1글자 ~ 4글자까지
nouns1 = sapply(nouns, function(x) {
  Filter(function(y) { nchar(y) <= 4 && nchar(y) > 1 && is.hangul(y) }, x)
})



wtrans = as(nouns1, "transactions")
class(wtrans)
rules = apriori(nouns1, parameter = list(supp=0.1, conf=0.5))



#         
subrules2 <- head(sort(rules, by="lift"), 20) ## lift 기준으로 상위 20개만을 시각화
ig <- plot( subrules2, method="graph", control=list(type="items") )
subrules2 <- head(sort(rules, by="confidence"), 30)

#
ig <- plot( subrules2, method="graph", control=list(type="items") )
# saveAsGraph seems to render bad DOT for this case
ig_df <- get.data.frame( ig, what = "both" )
#
visNetwork(
  nodes = data.frame(id = ig_df$vertices$name,
                     value = ig_df$vertices$support, ig_df$vertices),
  edges = ig_df$edges
)
```

